# Database
DATABASE_URL="postgresql://lacylights:lacylights_dev_password@localhost:5432/lacylights"

# Server Configuration
PORT=4000
NODE_ENV=development

# CORS Configuration
CORS_ORIGIN=http://localhost:3000

# DMX Configuration
DMX_UNIVERSE_COUNT=4
DMX_REFRESH_RATE=44

# Session Configuration
SESSION_SECRET=your-session-secret-here

# Redis Configuration (optional - for session storage and caching)
REDIS_URL=redis://localhost:6379

# Docker Configuration
# Set to true when running in Docker container
DOCKER_MODE=false

# AI Assistant Configuration
# Choose your LLM provider: claude, openai, or local
LLM_PROVIDER=claude

# For Claude (Anthropic)
ANTHROPIC_API_KEY=your_anthropic_api_key_here
# Available models: claude-3-sonnet-20240229, claude-3-haiku-20240307, claude-3-opus-20240229
# Note: claude-4 models may require different naming - check Anthropic docs
CLAUDE_MODEL=claude-3-sonnet-20240229

# For OpenAI
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4

# For Local LLM (e.g., Ollama)
LOCAL_LLM_ENDPOINT=http://localhost:11434/api/generate
LOCAL_LLM_MODEL=llama2
